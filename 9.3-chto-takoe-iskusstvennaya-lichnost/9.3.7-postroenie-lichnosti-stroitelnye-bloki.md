# 9.3.7 Построение личности - строительные блоки

Давайте рассмотрим, какие у нас есть части для нашего робота с искусственной личностью? У нас есть инструменты для симуляции эмоций. У нас есть конечный автомат с шестью типами эмоции, которые мы можем смешивать. У нас есть предыстория или биография личной информации робота. Мы выбрали личность для эмуляции. У нас есть концепция игрового движка, в которой робот пытается набрать очки за получение информации, участвуя в легкой беседе или фатическом общении. Робот будет менять свои эмоции на основе разговоров. Эмоции будут выражаться либо спрашивая робота, как он себя чувствует, либо через язык тела, выраженный робо-рукой.

Теперь нам нужна какая-то структура, чтобы собрать все эти части вместе, которая может хотя бы как-то вести разговор, и которую мы можем регулировать и манипулировать. Для этого мы снова посетим старого, старого друга. Знакомьтесь с **ELIZA**.

ELIZA - это, вероятно, самая первая программа-разговорная система. Она была изобретена в 1964 году Джозефом Вайценбаумом, профессором Массачусетского технологического института, еврейским немецким беженцем Второй мировой войны, и человеком, считающимся одним из отцов искусственного интеллекта.

ELIZA была названа в честь Элизы Дулиттл, главной героини в книге Джорджа Бернарда Шоу _Пигмалион_. В греческой мифологии Пигмалион был скульптором, который влюбился в одну из своих статуй. Он молился Афродите, которая удовлетворила его желание, чтобы статуя ожила. Это очень похоже на то, что мы сейчас делаем - приводим нашего робота к симулированной жизни через эту странную цепочку событий, названий и греческой мифологии.

ELIZA была симуляцией роджерского терапевта. Что ещё за роджерский терапевт? Согласно _«Психологии сегодня»_ \([https://www.psychologytoday.com/us/blog/whatdoesnt-kill-us/201210/unconditional-positive-regard](https://www.psychologytoday.com/us/blog/whatdoesnt-kill-us/201210/unconditional-positive-regard)\), Карл Роджерс является основателем «Клиент-центрированной терапии», которая верит в UPR - Безусловное Положительное Отношение. Что означает, что терапевт держит свои мнения при себя во время сеансов терапии, и в первую очередь отражает слова пациента обратно на него. Если пациент говорит: _«я всегда ненавидел кошек»_ -, психотерапевт может ответить: _«Почему вы думаете, что ненавидите кошек?»_ - вместо того, чтобы сказать: _«У меня есть кошка и они очень милые существа»_. Итак, ELIZA, компьютерная программа, отражает то, что вы говорите, не вставляя замечания. Вы разговариваете с ELIZA через то, что мы теперь называем текстовые сообщения, и то, что раньше мы называли печатанием. Вот фактическое ELIZA-взаимодействие между мной и open source версией ELIZA Уэйда Брейнерда, которую можно найти на [https://github.com/wadetb/eliza](https://github.com/wadetb/eliza). Пользователь печатает с символом &gt;. Кстати, `I hate cats` - это всего лишь пример. Пожалуйста, не говорите моей кошке об этом примере:

```text
ELIZA: How do you do. Please tell me your problem.
> I hate cats. 
You say you hate cats? 
> Yes. 
You seem to be quite positive. 
> I hate cats. 
Can you elaborate on that?
> I don't like cats because they smell bad. 
Don't you really like cats because they smell bad? 
> No. Don't like cats. 
Are you saying no just to be negative? 
> No. 
You are being a bit negative. 
> I am 
Is it because you are that you came to me? 
> No 
Why not?
> I am afraid of cats 
How long have you been afraid of cats? 
> About a year 
I'm not sure I understand you fully.
> 1 year 
Please go on. 
> I have been afraid of cats since the cat jumped on my head. 
Your head ? 
> yes
```

Таким образом, вы можете видеть, что ELIZA повторяет фразы обратно пользователю, отражая то, о чем пользователь говорит. Когда я сказал: _«I am afraid of cats»_, программа ответила: _«How long have you been afraid of cats?»_.

ELIZA проходит несколько этапов в распознавании и реагировании на предложения. Большая часть программы не в состоянии хардкода, и она работает на серии скриптов, которые вы можете редактировать и заменять, чтобы, по сути, перепрограммировать личность программы - вот почему мы сейчас говорим об ELIZA:

1.	В качестве первого шага, требуется разделить предложение на слова, разделенные пробелами. Программа также заменяет все заглавные буквы строчными.

2.	Программа заменяет альтернативные слова одним стандартным словом. Например, программа заменяет _cant_ на _can't_, если вы пропустили апостроф. Это называется **предобработка**.

3.	Программа ищет **ключевые слова**, о которых знает. Простое ключевое слово - _sorry_. Любое предложение с _sorry_ получает ответ по типу: _«please don’t apologize»_. Ключевые слова хранятся и приоритизируются в порядке их появления в файле скрипта.

4.	Программа ищет шаблоны **декомпозиции** для этого ключевого слова. Это собирает предложения в общие группы. Например, шаблон: _\* i was \*_, который можно прочитать как _«any word phrase – I was - any word phrase»_.

5.	ELIZA выбирает шаблон **пересборки** для составления ответа. Если у программы есть несколько вариантов ответов, она выбирает один наугад. В нашем шаблоне _\* i was \*_, один из возможных ответов это: _«Perhaps I already know you were»_ \(2\). Число \(2\) в скобках говорит программе заменить словосочетание, которое идет после _i was_ в предложении. Если вы написали: _«Then I was left at a bus station»_, ответ согласно шаблону может быть: _«Perhaps I already know you were left at a bus station»._ Вы также можете получить более прагматичное: _«Oh, really_». Важно знать, что ELIZA не имеет представления о содержании фраз - она просто манипулирует словами для составления предложений на основе шаблонов.

6.	ELIZA выполняет **постобработку** замен слов. Например, она заменяет слово _I_ словом _you_. Если вы наберете _«I went to sleep»_, программа ответит: _«You say you went to sleep?»_, что является последним правилом ответа после того, как все остальные исчерпаны.

Данные, которые контролируют личность ELIZA, называются **скриптом**. Он дает программе все правила формирования ответов. Скрипт для роджерского терапевта называется `DOCTOR`. Он содержит несколько приветственных слов, несколько заключительных слов при выходе из программы, список правил для процессов перед заменой, список замещающих слов постобработки, список синонимов и список ключевых слов с правилами декомпозиции и пересборки \(reasmb\).

Вот пример правила для ключевых слов _I am_:

```text
decomp: * i am * 
reasmb: Is it because you are (2) that you came to me ?
reasmb: How long have you been (2) ? 
reasmb: Do you believe it is normal to be (2) ? 
reasmb: Do you enjoy being (2) ?
```

Программа выбирает случайную фразу из четырех предоставленных. Если бы я сказал: _«I am afraid of cats»_, тогда бы это правило сработало, и сгенерировалась бы одна из этих четырех фраз. Программа спросила бы: _«Do you enjoy being afraid of cats?»_, или «_How long have you been afraid of cats?»_.

Почти весь диалог, созданный ELIZA, происходит из файла скрипта, делая таким образом ELIZA какого-то рода экспертной системой, основанной на правилах, а также предоставляя открытый фреймворк для создания новых приложений на основе голосовых систем.

Как и все компьютерные программы, концепции ELIZA для генерирования разговоров были расширены в общую \(то есть, не просто терапевт\), программу под названием ALICE, которая является ретронимом от «Искусственное лингвистическое интернет-компьютерное существо» \(Artificial Linguist Internet Computer Entity\). Обычный файл данных скрипта, используемый ELIZA, стал AIML, языком разметки для искусственного интеллекта \(Artificial Intelligence Markup Language\). ALICE была расширена, чтобы быть намного более полезной, чем когда-либо была ELIZA, и чтобы охватывать гораздо больше тем и возможностей. Тем не менее, ALICE сохраняет те же концепты пред- и пост- замещений, ключевых слов и шаблонов ответа. Существует плагин Mycroft, который позволяет Mycroft использовать файлы AIML, чтобы конструировать разговоры. Этот инструмент даёт отличный альтернативный конструктор для личности вашего робота. [https://github.com/forslund/fallback-aiml](https://github.com/forslund/fallback-aiml)

AIML выглядит так:

```text
<category>
<pattern>I PLAY *</pattern>
<template>Is <set_it><person/></set_it> a game or a musical  instrument?</template>
</category>
<category> 
<pattern>I PLAY THE *</pattern>
<template>I wish I played an instrument. My parents could not afford the lessons.
<think><set_it><set_does><settopic>play the
<person/></settopic></set_does></set_it></think></template>
 </category>
 <category>
 <pattern>I PRIDE MYSELF *</pattern>
 <template>It seems you have good self esteem.</template>
 </category>
 <category>
 <pattern>I QUIT MY JOB *</pattern>
 <template>Where did you work and why did you quit?</template>
 </category>
 <category>
 <pattern>I READ *</pattern>
 <template>I don't think I've read that. Can you give me a reference?
 <think><set_it><set_does><settopic>read
<person/></settopic></set_does></set_it></think></template>
 </category>
 <category>
 <pattern>I READ * BOOKS</pattern>
 <template>Name some books in that genre.
 <think><set_it><set_does><settopic>read <person/> books</settopic></set_does></set_it></think> 
 <think><set_personality>critical</set_personality></think></template>
 </category>
```

Источник: [http://www.digitalanywhere.com/projects/dany/index.html](http://www.digitalanywhere.com/projects/dany/index.html). ALICE - открытое ПО под лицензией GNU public license.

## Контекст

Одним из наиболее существенных недостатков ELIZA является полное отсутствие памяти. ELIZA помнит только предыдущее утверждение. Вы не можете говорить о своем отце, а затем сказать: _«He was a good man»_. ELIZA не будет понимать, о ком вы говорите. ELIZA понятия не имеет о контексте за пределами предыдущего предложения.

Что такое контекст? В ходе разговора мы часто сокращаем существительные до местоимений. Мы можем сказать: _«I like my dog»_, и в следующем предложении сказать: _«He is well behaved»_. На что ссылается _he_? Мы знаем, что на собаку, но как это узнает компьютер? Мы собираемся добавить способность рассуждать из контекста в нашу программу.

Мы собираемся создать объект-хранилище, который мы будем называть контекстной памятью. В этом объекте мы сможем не отставать от нескольких частей нашего разговора, включая человека, с которым мы разговариваем, последнюю тему, о которой мы говорили, задавали ли мы какие-либо вопросы, на которые все еще у нас нет ответа, и ответы на предыдущие вопросы, если они нам понадобятся снова. Компьютер будет предполагать, что местоимение, отличное от _I_, будет ссылаться на последнее подлежащее, какое бы оно ни было. Если я говорил о собаке, а потом сказал: _«He is so cute»_, то робот предположит, что я имею в виду собаку.

Ранее мы обсуждали игру, целью которой было получить информацию от нашего человека. Робот будет собирать и запоминать эту информацию даже после его выключения, чтобы в следующий раз, когда этот человек разговаривает с роботом, робот вспомнил информацию, которую он узнал до этого – точно так же, как вы помните информацию о друге. Если вы хотите продолжить расширять эту концепцию ИИ-чатбота, вы можете использовать эту информацию для создания дополнительного разговора. Например, если человек говорит, что ему нравится бейсбол, робот может спросить, какая у человека любимая команда, а затем посмотреть в интернете дату следующей бейсбольной игры.

Это конец нашего списка частей, которые мы собираемся использовать для создания личности робота. Теперь мы можем пойти дальше и использовать наш конструктор личности. Я собираюсь использовать скелет программы ELIZA с открытым ПО на Python от Уэйда Брейнерда, чтобы построить личность Альберта Tinman.

В интересах времени и места я собираюсь разместить здесь только те части, которые я добавил в базовую программу. Весь код будет в репозитории GitHub. Вы можете получить оригинальную программу по ссылке [https://github.com/wadetb/eliza](https://github.com/wadetb/eliza), если вы хотите следовать вместе с этой книгой.

